{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c681121",
   "metadata": {},
   "source": [
    "# HW3 3주차 강의 요약\n",
    "\n",
    "## 2021년 09월 26일 안상호\n",
    "\n",
    "\n",
    "1. 텍스트 마이닝 개요\n",
    "2. 학습을 위한 사전 지식\n",
    "3. 텍스트 마이닝 방법론\n",
    "4. 텍스트 마이닝 단계\n",
    "5. 텍스트 마이닝 응용\n",
    "6. 텍스트 마이닝 도구 \n",
    "7. BOW/TF-IDF 기반 텍스트 분류 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cf86dd",
   "metadata": {},
   "source": [
    "# 1. 텍스트 마이닝 개요\n",
    "\n",
    "---\n",
    "\n",
    "> 텍스트 마이닝이란 **텍스트**로부터 *고품질의 정보*를 추출하는 과정 (pattern and trends)\n",
    "\n",
    "- 비정형 텍스트 데이터를 분석이 가능한 **정형 데이터**로 변환\n",
    "    + NLP를 비롯한 다양한 분석 방법론\n",
    "- 텍스트는 가변 길이 이므로 **일정한 길이의 벡터**로 변환 (수치)\n",
    "    + 이렇게하면 머신러닝에 적용하기 용이하며, 워드 임베딩을 하는 이유!\n",
    "    \n",
    "### 텍스트 마이닝의 목적\n",
    "\n",
    "- text classification\n",
    "- clustering\n",
    "- sentiment analysis\n",
    "- document summarization\n",
    "- machine translation\n",
    "- prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5687fb8c",
   "metadata": {},
   "source": [
    "# 2. 학습을 위한 사전 지식\n",
    "\n",
    "---\n",
    "\n",
    "### 자연어 처리 (NLP; Natural Language Processing)\n",
    "\n",
    "- 텍스트라는 단어들의 연속된 시퀀스를 수치화된 벡터로 변환\n",
    "\n",
    "### 통계학 & 선형대수\n",
    "\n",
    "- 조건부 확률, 벡터(Vector), 선형 결합(Linear Combination)\n",
    "\n",
    "### 머신러닝\n",
    "- 회귀분석의 개념\n",
    "- 머신러닝의 다양한 기법 (나이브 베이즈, Decision Tree, etc)\n",
    "\n",
    "\n",
    "### 딥러닝\n",
    "- 딥러닝의 개념\n",
    "- 딥러닝의 다양한 기법(CNN, RNN, etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22194b5f",
   "metadata": {},
   "source": [
    "# 3. 텍스트 마이닝 방법론\n",
    "\n",
    "---\n",
    "\n",
    "- NLP 기본 도구\n",
    "    + Tokenize, Stemming, Lemmatize\n",
    "    + Chunking\n",
    "    + BOW, TF-IDF: **Sparse** Representation\n",
    "\n",
    "- 머신러닝/딥러닝\n",
    "    + Naive Bayes, Logistic Regression, Decision Tree, SVM\n",
    "    + Word Embedding(Word2Vec, Doc2Vec): **Dense** Representation\n",
    "    + RNN(LSTM), Attention, Transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0580d45",
   "metadata": {},
   "source": [
    "# 4. 텍스트 마이닝 단계\n",
    "\n",
    "---\n",
    "\n",
    "```\n",
    "document = 텍스트 마이닝의 대상\n",
    "```\n",
    "\n",
    "1. `document` $\\rightarrow$ tokenize(단어 단위로 쪼갬)와 normalize(단어의 원형으로 회귀) 작업 진행\n",
    "2. 순서가 의미 있는 단어들의 Sequence를 생성\n",
    "    - Fixed size vector **without** sequence info\n",
    "    - Fixed size vector **with** sequence info\n",
    "    - Series of **Word Embedding** with sequence info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7bf5b8",
   "metadata": {},
   "source": [
    "# 5. 텍스트 마이닝 응용\n",
    "\n",
    "---\n",
    "\n",
    "### Document Classification\n",
    "\n",
    "> `Sentiment Analysis`, `Sentiment Classification`\n",
    "\n",
    "### Document Generation\n",
    "> `Q&A`, `Summarization`, `Translation`\n",
    "\n",
    "\n",
    "### Keyword Extraction\n",
    "> `Tagging/Annotation`\n",
    "\n",
    "### Topic Modeling\n",
    "\n",
    "> `Latent Semantic Analysis`(**LSA**), `Latent Dirichlet Allocation`(**LDA**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f893aae",
   "metadata": {},
   "source": [
    "# 6. 텍스트 마이닝 도구\n",
    "\n",
    "---\n",
    "\n",
    "### 파이썬 라이브러리\n",
    "\n",
    "- NLTK\n",
    "    + 가장 유명한 NLP 라이브러리로 영어 대상 우수한 성능 (띄어쓰기 기반)\n",
    "- Scikit-Learn\n",
    "    + 머신러닝 라이브러리\n",
    "    + 기본적인 NLP, 텍스트 마이닝 도구 지원\n",
    "- Gensim\n",
    "    + Word2Vec으로 유명\n",
    "    + 기본적인 NLP, 텍스트 마이닝 도구 지원\n",
    "- Keras(TF) / Pytorch \n",
    "    + RNN, Seq2Seq 등 딥러닝 위주 라이브러리 제공\n",
    "\n",
    "\n",
    "\n",
    "### 기본 도구\n",
    "\n",
    "> 목적: `document` 나 `sentence`를 Sparse Vector로 변환\n",
    "\n",
    "- Tokenize\n",
    "    + 대상이 되는 문서나 문장을 최소 단위로 쪼갬\n",
    "- Normalization\n",
    "    + 쪼개진 최소 단위를 표준화\n",
    "- POS-tagging\n",
    "    + 최소 의미 단위로 나누어진 대상에 대한 품사를 태깅\n",
    "- Chunking\n",
    "    + POS-tagging 결과를 명사구, 형용사구, 분사구 등과 같은 말 모듬으로 재결합\n",
    "- BOW(bag-of-words), TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "    + tokenize된 결과를 이용하여 문서를 vector로 표현\n",
    "    \n",
    "![BOW](http://hleecaster.com/wp-content/uploads/2020/01/bow01.jpg)\n",
    "\n",
    "![TF-IDF](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/BoWBag-of-Words-model-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d8041d",
   "metadata": {},
   "source": [
    "# 7. BOW/TF-IDF 기반 텍스트 분류\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb03bdf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
